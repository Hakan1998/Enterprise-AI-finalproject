{"cells":[{"cell_type":"markdown","metadata":{},"source":["Final Project Group 4 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install zenml\n","!pip install nltk\n","!pip install surprise\n","!zenml init"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 3)\u001b[1;35m.\u001b[0m\n","\u001b[1;35mExecuting a new run.\u001b[0m\n","\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36mfeature_engineering_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml up\u001b[1;35m.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has started.\u001b[0m\n","/workspaces/enterpriseai/steps/feature_engineering/movie_data/load_movie_data.py:16: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv(filename)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.926s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.546s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.759s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.696s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.786s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.239s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.924s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.229s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m8.963s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 1)\u001b[1;35m.\u001b[0m\n","\u001b[1;35mExecuting a new run.\u001b[0m\n","\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36mtraining_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml up\u001b[1;35m.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mFailed to extract metadata for output artifact 'training_pipeline::convert_to_surprise_format::output_2': unsupported operand type(s) for +: 'dict' and 'dict'\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.637s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.691s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.505s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","SVD Metrics: (0.9644866131438485, 0.7579057646351192, 0.4945626696274365, 0.785752323381857)\n","KNN Metrics: (1.1414231569217281, 0.8863067186224065, 0.5722664281602104, 0.8892764618800889)\n","Baseline Metrics: (0.9682811041906763, 0.7660352970518614, 0.5043486306439675, 0.8044103133481373)\n","Content-based Model Precision: 0.045454545454545456\n","Content-based Model Recall: 0.5555555555555556\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m has finished in \u001b[0m\u001b[1;36m2.493s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m6.886s\u001b[1;35m.\u001b[0m\n","<zenml.steps.entrypoint_function_utils.StepArtifact object at 0x738ac7f80d60>\n","\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36minference_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 4)\u001b[1;35m.\u001b[0m\n","\u001b[1;35mExecuting a new run.\u001b[0m\n","\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36minference_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml up\u001b[1;35m.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mFailed to extract metadata for output artifact 'inference_pipeline::convert_to_surprise_format::output_2': unsupported operand type(s) for +: 'dict' and 'dict'\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.571s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has started.\u001b[0m\n","/workspaces/enterpriseai/steps/feature_engineering/movie_data/load_movie_data.py:16: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv(filename)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.606s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.108s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.968s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.533s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.416s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.723s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.640s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.213s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmake_predictions\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmake_predictions\u001b[1;35m has finished in \u001b[0m\u001b[1;36m8.329s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmake_predictions\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.796s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.421s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m22.227s\u001b[1;35m.\u001b[0m\n"]}],"source":["!python run.py"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All artifact names:\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 17, 943676), updated=datetime.datetime(2024, 7, 4, 13, 38, 17, 943680), tags=[], latest_version_name='21', latest_version_id=UUID('ea97357f-cacc-42a4-82f2-01dabe39d82f')) metadata=None resources=None id=UUID('134db705-3408-4b5f-b5d5-45c5c48489d0') permission_denied=False name='input_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 19, 395390), updated=datetime.datetime(2024, 7, 4, 13, 38, 19, 395394), tags=[], latest_version_name='21', latest_version_id=UUID('333e9ca6-6357-4ddc-b41c-0f5dc47347ff')) metadata=None resources=None id=UUID('c2ae9d6d-1d57-4dd7-a748-cbaebbf78683') permission_denied=False name='rating_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 20, 896223), updated=datetime.datetime(2024, 7, 4, 13, 38, 20, 896227), tags=[], latest_version_name='21', latest_version_id=UUID('7212a849-7abc-494c-bd6d-44e923d4f684')) metadata=None resources=None id=UUID('edba22f2-797a-40f8-b25b-f4e7128ae233') permission_denied=False name='clean_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 22, 78244), updated=datetime.datetime(2024, 7, 4, 13, 38, 22, 78248), tags=[], latest_version_name='21', latest_version_id=UUID('348c85cc-f781-4c87-88be-2b9dbb6a64c4')) metadata=None resources=None id=UUID('9ca06de8-a182-4451-9e09-a57d30f633cd') permission_denied=False name='processed_ratings'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 23, 301146), updated=datetime.datetime(2024, 7, 4, 13, 38, 23, 301149), tags=[], latest_version_name='21', latest_version_id=UUID('78863acf-47b3-4618-9054-683cb99d5264')) metadata=None resources=None id=UUID('dbfa593f-cd52-4cf7-b9dc-604f481db094') permission_denied=False name='merged_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 23, 807664), updated=datetime.datetime(2024, 7, 4, 13, 38, 23, 807666), tags=[], latest_version_name='12', latest_version_id=UUID('11c1ff5f-4c84-442d-b799-0f467ad1c499')) metadata=None resources=None id=UUID('276ef757-8ff5-4f8b-b77a-8ea97c1f267e') permission_denied=False name='feature_engineering_pipeline::create_preprocessing_pipeline::output'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 24, 106912), updated=datetime.datetime(2024, 7, 4, 13, 38, 24, 106914), tags=[], latest_version_name='21', latest_version_id=UUID('0fa8e1b3-0adf-4750-9470-f3cc5d04d288')) metadata=None resources=None id=UUID('7a3696c7-62ae-4cca-8174-877b0b406160') permission_denied=False name='train_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 24, 451759), updated=datetime.datetime(2024, 7, 4, 13, 38, 24, 451761), tags=[], latest_version_name='21', latest_version_id=UUID('a245ab21-f4c1-4412-8b38-f66df7200d91')) metadata=None resources=None id=UUID('1a2a7651-22f4-46d0-8eaa-2673fcaaeb7f') permission_denied=False name='test_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 25, 9964), updated=datetime.datetime(2024, 7, 4, 13, 38, 25, 9967), tags=[], latest_version_name='21', latest_version_id=UUID('49d1dcef-a96a-4d01-b493-12f55e2b71ff')) metadata=None resources=None id=UUID('65ec1040-ac49-4cb8-98c1-8bf0e53d2340') permission_denied=False name='train_data_preprocessed'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 25, 395112), updated=datetime.datetime(2024, 7, 4, 13, 38, 25, 395116), tags=[], latest_version_name='21', latest_version_id=UUID('a39c4ec3-c46c-40a3-ab10-e8f19117b4c6')) metadata=None resources=None id=UUID('5e0060b2-9158-4469-a53a-cb4b05159bc6') permission_denied=False name='test_data_preprocessed'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 25, 783334), updated=datetime.datetime(2024, 7, 4, 13, 38, 25, 783336), tags=[], latest_version_name='21', latest_version_id=UUID('4a22b812-23de-4152-8086-7467052742d7')) metadata=None resources=None id=UUID('51f4dca6-11fa-4071-be88-6c6b714e065e') permission_denied=False name='pipeline'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 27, 302010), updated=datetime.datetime(2024, 7, 4, 13, 38, 27, 302012), tags=[], latest_version_name='12', latest_version_id=UUID('b2fb0686-db2c-42f3-bf36-e5eb3cfb15ba')) metadata=None resources=None id=UUID('e4c8438d-4fd8-4fb5-a971-372d746a03bc') permission_denied=False name='training_pipeline::convert_to_surprise_format::output_0'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 27, 440657), updated=datetime.datetime(2024, 7, 4, 13, 38, 27, 440659), tags=[], latest_version_name='12', latest_version_id=UUID('8a3a906d-5545-44d2-a68c-ed9a916e7175')) metadata=None resources=None id=UUID('fe708dd0-e96d-4f35-a7ed-d9f4f87cfa9b') permission_denied=False name='training_pipeline::convert_to_surprise_format::output_1'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 27, 581373), updated=datetime.datetime(2024, 7, 4, 13, 38, 27, 581375), tags=[], latest_version_name='12', latest_version_id=UUID('202eb5d3-3079-4442-a75d-ac415a501552')) metadata=None resources=None id=UUID('368e95ba-4a19-4991-9f96-c7a39e82e7f8') permission_denied=False name='training_pipeline::convert_to_surprise_format::output_2'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 28, 219668), updated=datetime.datetime(2024, 7, 4, 13, 38, 28, 219671), tags=[], latest_version_name='12', latest_version_id=UUID('21eae699-c889-491b-a8b5-acfc6c079ead')) metadata=None resources=None id=UUID('551e3595-6a79-4ea2-80eb-78a5afa66846') permission_denied=False name='training_pipeline::hp_tuner::output_0'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 28, 343745), updated=datetime.datetime(2024, 7, 4, 13, 38, 28, 343748), tags=[], latest_version_name='12', latest_version_id=UUID('426ce3fe-7b6d-46b4-b30b-0f7a40107b36')) metadata=None resources=None id=UUID('7077ae6f-6189-4676-80a2-ecb3472dc972') permission_denied=False name='training_pipeline::hp_tuner::output_1'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 28, 475485), updated=datetime.datetime(2024, 7, 4, 13, 38, 28, 475489), tags=[], latest_version_name='12', latest_version_id=UUID('04dee187-5078-4dcd-8cef-36108147967b')) metadata=None resources=None id=UUID('9fcd1e6f-374d-451a-a101-46e7063e5707') permission_denied=False name='training_pipeline::hp_tuner::output_2'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 28, 602119), updated=datetime.datetime(2024, 7, 4, 13, 38, 28, 602121), tags=[], latest_version_name='12', latest_version_id=UUID('a7353a81-dacb-4f4f-b536-5c7700eaabd9')) metadata=None resources=None id=UUID('cbd1364c-4602-42b2-8e20-0e4a8bd3acb3') permission_denied=False name='training_pipeline::hp_tuner::output_3'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 29, 103203), updated=datetime.datetime(2024, 7, 4, 13, 38, 29, 103207), tags=[], latest_version_name='12', latest_version_id=UUID('6e9f85fd-1f43-4757-8b81-446a8b0060bc')) metadata=None resources=None id=UUID('47f7f934-d97f-4c3b-98a9-952840f8d7ac') permission_denied=False name='training_pipeline::model_trainer::output_0'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 4, 13, 38, 29, 237946), updated=datetime.datetime(2024, 7, 4, 13, 38, 29, 237948), tags=[], latest_version_name='12', latest_version_id=UUID('b98ca7fd-5237-492a-9373-dcc5d43ed235')) metadata=None resources=None id=UUID('bf8926f9-bac3-4d9c-98ee-78487e03ddb9') permission_denied=False name='training_pipeline::model_trainer::output_1'\n"]}],"source":["from zenml.client import Client\n","def print_all_artifact_names():\n","    client = Client()\n","    artifact_names = client.list_artifacts()\n","    print(\"All artifact names:\")\n","    for artifact_name in artifact_names:\n","        print(artifact_name)\n","\n","if __name__ == \"__main__\":\n","    print_all_artifact_names()"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["<surprise.prediction_algorithms.knns.KNNBasic at 0x77e6a5418220>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["from zenml.client import Client\n","artifact = Client().get_artifact_version(\"training_pipeline::model_trainer::output_1\")\n","artifact.load()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Repository Directory Structure:\n","📂 materializers\n","    📄 surprise_materializers.py\n","📂 .zen\n","    📄 config.yaml\n","📄 devcontainer.json\n","📄 launch.json\n","📄 config.yaml\n","📄 main.ipynb\n","📄 .gitignore\n","📄 run.py\n","📂 pipelines\n","    📄 inference_pipeline.py\n","    📂 __pycache__\n","        📄 __init__.cpython-310.pyc\n","        📄 training_pipeline.cpython-310.pyc\n","        📄 feature_engineering_pipeline.cpython-310.pyc\n","    📄 training_pipeline.py\n","    📄 __init__.py\n","    📄 feature_engineering_pipeline.py\n","📂 .git\n","    📄 HEAD\n","    📄 packed-refs\n","    📂 logs\n","        📄 HEAD\n","        📂 refs\n","            📂 heads\n","                📄 Main_after_Feature-Engineering-from-Emma\n","            📂 remotes\n","                📂 origin\n","                    📄 emma\n","                    📄 Hakan\n","                    📄 main\n","                    📄 Silas\n","    📄 FETCH_HEAD\n","    📂 lfs\n","        📂 tmp\n","    📄 description\n","    📂 info\n","        📄 exclude\n","    📄 COMMIT_EDITMSG\n","    📂 hooks\n","        📄 sendemail-validate.sample\n","        📄 commit-msg.sample\n","        📄 applypatch-msg.sample\n","        📄 fsmonitor-watchman.sample\n","        📄 pre-commit.sample\n","        📄 push-to-checkout.sample\n","        📄 pre-rebase.sample\n","        📄 pre-push.sample\n","        📄 prepare-commit-msg.sample\n","        📄 pre-merge-commit.sample\n","        📄 post-update.sample\n","        📄 pre-applypatch.sample\n","        📄 update.sample\n","        📄 pre-receive.sample\n","    📄 config\n","    📂 objects\n","        📂 0c\n","            📄 8eedc24bb4f13a9caf8913868218b66e10e9a7\n","        📂 f3\n","            📄 e7c2b67e19516565e80aa0d90ec51fa20f9c77\n","        📂 9e\n","            📄 72f3d1b4b2de7847392ff51bc1cd01b51d6c34\n","        📂 8e\n","            📄 2df1551b433c998d7f7558463b54624d2faa2a\n","        📂 info\n","        📂 51\n","            📄 361820043aa49272eac80ebaa7bd83d877e948\n","        📂 bf\n","            📄 087ee445c41cbd4f539c1508fa6ef811ed438e\n","        📂 8f\n","            📄 91d40aa4c78c16738ae0c332c21a3f7a9b3c83\n","        📂 e3\n","            📄 e46fc29391ccbdf29ef3be3a5b54a0621e32cc\n","        📂 b2\n","            📄 2122cb7b0d3b02b3610d623571486a882dab72\n","        📂 7a\n","            📄 9147ee2a9014c488733d44b9b2a2c16e674d79\n","        📂 93\n","            📄 de988a676989f89fed4e0849ae8a4dca8e6f3e\n","            📄 ed3675c2d2690a79d7155a07d08952e00f6c4b\n","        📂 ea\n","            📄 d8d030e1924f64c709624cdf51bb604fb7429b\n","        📂 b4\n","            📄 0c8cee27d533e5919b7ffcabbb172874c87c5e\n","        📂 0f\n","            📄 ecfa3303eedf5d41dbbba61885c21fc67d2e50\n","        📂 60\n","            📄 a868877f25c7e2bff5594b606746cbedb46da7\n","        📂 49\n","            📄 3401745197d52675d0f2f9ac91b11132188936\n","        📂 ec\n","            📄 5a0b514b837b4e4d600032a18ae2b17e35bc86\n","        📂 38\n","            📄 adc7e3b4a112385ba089f50a878674bf006171\n","        📂 pack\n","            📄 pack-4f42ab96472c293d8b07e1fc6e10645e61a77b98.idx\n","            📄 pack-a644e7e91fabbaf5a2a33e13bdbdf1c25bbf7e34.pack\n","            📄 pack-a644e7e91fabbaf5a2a33e13bdbdf1c25bbf7e34.rev\n","            📄 pack-4f42ab96472c293d8b07e1fc6e10645e61a77b98.rev\n","            📄 pack-a644e7e91fabbaf5a2a33e13bdbdf1c25bbf7e34.idx\n","            📄 pack-4f42ab96472c293d8b07e1fc6e10645e61a77b98.pack\n","        📂 98\n","            📄 03772b5c6384a35b4fff4f071872e871740b7e\n","    📂 refs\n","        📂 heads\n","            📄 Main_after_Feature-Engineering-from-Emma\n","        📂 tags\n","        📂 remotes\n","            📂 origin\n","                📄 emma\n","                📄 Hakan\n","                📄 main\n","                📄 Silas\n","    📄 index\n","    📂 branches\n","📄 README.md\n","📄 .DS_Store\n","📂 steps\n","    📂 training\n","        📄 model_trainer.py\n","        📄 evaluate_model.py\n","        📂 __pycache__\n","            📄 convert_to_surprise_format.cpython-310.pyc\n","            📄 model_trainer.cpython-310.pyc\n","            📄 hp_tuner.cpython-310.pyc\n","            📄 evaluate_model.cpython-310.pyc\n","        📄 convert_to_surprise_format.py\n","        📄 hp_tuner.py\n","    📂 __pycache__\n","        📄 utils.cpython-310.pyc\n","        📄 __init__.cpython-310.pyc\n","    📄 __init__.py\n","    📂 feature_engineering\n","        📂 __pycache__\n","            📄 create_preprocessing_pipeline.cpython-310.pyc\n","            📄 split_data.cpython-310.pyc\n","            📄 feature_preprocessor.cpython-310.pyc\n","            📄 merged_data.cpython-310.pyc\n","        📂 movie_data\n","            📄 load_movie_data.py\n","            📂 __pycache__\n","                📄 load_movie_data.cpython-310.pyc\n","                📄 clean_movie_data.cpython-310.pyc\n","            📄 clean_movie_data.py\n","        📄 merged_data.py\n","        📄 split_data.py\n","        📄 create_preprocessing_pipeline.py\n","        📂 user_profile\n","            📂 __pycache__\n","                📄 load_rating_data.cpython-310.pyc\n","                📄 preprocess_rating_data.cpython-310.pyc\n","            📄 preprocess_rating_data.py\n","            📄 load_rating_data.py\n","        📄 feature_preprocessor.py\n","    📂 inference\n","        📄 __init__.py\n","        📄 load_inference_rating.py\n","    📄 utils.py\n","📂 data\n","    📄 ratings_small.csv\n","    📄 movies_metadata.csv\n","    📄 inference_ratings.csv\n"]}],"source":["import os\n","\n","def print_directory_structure(start_path='.', indent=''):\n","    for item in os.listdir(start_path):\n","        item_path = os.path.join(start_path, item)\n","        if os.path.isdir(item_path):\n","            print(indent + '📂 ' + item)\n","            print_directory_structure(item_path, indent + '    ')\n","        else:\n","            print(indent + '📄 ' + item)\n","\n","if __name__ == \"__main__\":\n","    print(\"Repository Directory Structure:\")\n","    print_directory_structure()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l\u001b[2;36mFound existing ZenML repository at path \u001b[0m\u001b[2;32m'/workspaces/enterpriseai'\u001b[0m\u001b[2;36m.\u001b[0m\n","\u001b[2;32m⠋\u001b[0m\u001b[2;36m Initializing ZenML repository at /workspaces/enterpriseai.\u001b[0m\n","\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Initializing ZenML repository at /workspaces/enterpriseai.\n","\n","\u001b[1A\u001b[2K\u001b[1A\u001b[2K"]}],"source":["\n","!zenml init"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
