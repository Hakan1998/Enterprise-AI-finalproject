{"cells":[{"cell_type":"markdown","metadata":{},"source":["Final Project Group 4 "]},{"cell_type":"markdown","metadata":{},"source":["Install Librarys"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install zenml\n","!pip install nltk\n","!pip install surprise\n","!zenml init"]},{"cell_type":"markdown","metadata":{},"source":["Run the Pipeline"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 1)\u001b[1;35m.\u001b[0m\n","\u001b[1;35mExecuting a new run.\u001b[0m\n","\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36mfeature_engineering_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mDashboard URL: http://127.0.0.1:8237/runs/aee2c50a-889e-4e2c-9e4b-86ebdfaf30ee\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has started.\u001b[0m\n","/workspaces/enterpriseai/steps/feature_engineering/movie_data/load_movie_data.py:16: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv(filename)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.905s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.779s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.803s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.876s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.962s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.648s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.994s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.444s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m10.691s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 6)\u001b[1;35m.\u001b[0m\n","\u001b[1;35mExecuting a new run.\u001b[0m\n","\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36mtraining_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mDashboard URL: http://127.0.0.1:8237/runs/0e49c9ff-5458-45ee-b27c-9ff1b12b91da\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mFailed to extract metadata for output artifact 'Test Data': unsupported operand type(s) for +: 'dict' and 'dict'\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.854s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.472s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.random_pred.NormalPredictor'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.random_pred.NormalPredictor'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.NMF'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.NMF'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.slope_one.SlopeOne'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.slope_one.SlopeOne'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m2.496s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","SVD Metrics: (0.9627373719178753, 0.7564999518118437, 0.4899179620034543, 0.784898017929106)\n","KNN Metrics: (1.1414231569217281, 0.8863067186224065, 0.5722664281602104, 0.8892764618800889)\n","Baseline Metrics: (0.9682811041906763, 0.7660352970518614, 0.5043486306439675, 0.8044103133481373)\n","NormalPredictor Metrics: (1.4027952314480647, 1.1121524240189637, 0.3483993338267949, 0.624865326095896)\n","NMF Metrics: (1.003900373757517, 0.7927545578313029, 0.4096811004194424, 0.6892990788716176)\n","SlopeOne Metrics: (1.1897287062639512, 0.9291046891546882, 0.4571541656386216, 0.7379400032897442)\n","Content-based Model Precision: 0.045454545454545456\n","Content-based Model Recall: 0.5555555555555556\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m has finished in \u001b[0m\u001b[1;36m2.580s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m12.829s\u001b[1;35m.\u001b[0m\n","<zenml.steps.entrypoint_function_utils.StepArtifact object at 0x71ee5c223100>\n","\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36minference_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 9)\u001b[1;35m.\u001b[0m\n","\u001b[1;35mExecuting a new run.\u001b[0m\n","\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36minference_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n","\u001b[1;35mDashboard URL: http://127.0.0.1:8237/runs/eb3c7344-7689-493e-832e-4dece6d382ce\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.dataset.DatasetAutoFolds'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.trainset.Trainset'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mFailed to extract metadata for output artifact 'Test Data': unsupported operand type(s) for +: 'dict' and 'dict'\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.818s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mconvert_to_surprise_format\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has started.\u001b[0m\n","/workspaces/enterpriseai/steps/feature_engineering/movie_data/load_movie_data.py:16: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv(filename)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m2.012s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.567s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mload_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.919s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mclean_movie_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using als...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","Estimating biases using sgd...\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.207s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuner\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.622s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mpreprocess_rating_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.889s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmerged_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Estimating biases using als...\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.knns.KNNBasic'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.baseline_only.BaselineOnly'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.random_pred.NormalPredictor'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.random_pred.NormalPredictor'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.NMF'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.matrix_factorization.NMF'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.slope_one.SlopeOne'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'surprise.prediction_algorithms.slope_one.SlopeOne'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m2.583s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.571s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmake_predictions\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[33mNo materializer is registered for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[1;36m<class 'numpy.int64'>\u001b[33m according to the instructions at https://docs.zenml.io/how-to/handle-data-artifacts/handle-custom-data-types\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmake_predictions\u001b[1;35m has finished in \u001b[0m\u001b[1;36m9.402s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mmake_predictions\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.135s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has started.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","/usr/local/python/3.10.13/lib/python3.10/site-packages/zenml/materializers/pandas_materializer.py:99: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = pd.read_csv(f, index_col=0, parse_dates=True)\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[33mBy default, the \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m stores data as a \u001b[0m\u001b[1;36m.csv\u001b[33m file. If you want to store data more efficiently, you can install \u001b[0m\u001b[1;36mpyarrow\u001b[33m by running '\u001b[0m\u001b[1;36mpip install pyarrow\u001b[33m'. This will allow \u001b[0m\u001b[1;36mPandasMaterializer\u001b[33m to automatically store the data as a \u001b[0m\u001b[1;36m.parquet\u001b[33m file instead.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.664s\u001b[1;35m.\u001b[0m\n","\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m completed successfully.\u001b[0m\n","\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m31.193s\u001b[1;35m.\u001b[0m\n"]}],"source":["!python run.py"]},{"cell_type":"markdown","metadata":{},"source":["Print all Artifacts\n","- for some unknow reason not all Artifacts are shown here is better to always look at the dashboard below"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All artifact names:\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 42, 58, 125205), updated=datetime.datetime(2024, 7, 5, 8, 42, 58, 125209), tags=[], latest_version_name='10', latest_version_id=UUID('ddd17f7f-c9e6-450e-9cdc-31c425c2d31e')) metadata=None resources=None id=UUID('15861564-0a9c-48ca-9080-b2c0ee818af0') permission_denied=False name='input_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 0, 16959), updated=datetime.datetime(2024, 7, 5, 8, 43, 0, 16963), tags=[], latest_version_name='10', latest_version_id=UUID('2712fc1b-860f-4e65-9dce-12510c211438')) metadata=None resources=None id=UUID('9f579672-254a-4555-adf0-dd622f6a782a') permission_denied=False name='rating_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 1, 819272), updated=datetime.datetime(2024, 7, 5, 8, 43, 1, 819276), tags=[], latest_version_name='10', latest_version_id=UUID('35d849f9-644d-44f6-a489-c33f68e8e624')) metadata=None resources=None id=UUID('193f6145-778c-4d65-9e77-3b5ebd67e0b4') permission_denied=False name='clean_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 3, 32456), updated=datetime.datetime(2024, 7, 5, 8, 43, 3, 32460), tags=[], latest_version_name='10', latest_version_id=UUID('29700f30-fc01-4951-9612-1f5a430511b4')) metadata=None resources=None id=UUID('6f947be4-b5fe-48a4-bad5-787d35165c7e') permission_denied=False name='processed_ratings'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 4, 223549), updated=datetime.datetime(2024, 7, 5, 8, 43, 4, 223552), tags=[], latest_version_name='10', latest_version_id=UUID('625de678-cb6f-4cb3-b3a5-08688a181a1f')) metadata=None resources=None id=UUID('a9b8d87a-9cc2-488a-bdd4-e0ba1d3eaaef') permission_denied=False name='merged_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 4, 875251), updated=datetime.datetime(2024, 7, 5, 8, 43, 4, 875254), tags=[], latest_version_name='6', latest_version_id=UUID('ab2b11cc-c986-4b49-9495-270d777fda55')) metadata=None resources=None id=UUID('565b8622-24ad-4725-a51e-409ac2c14a10') permission_denied=False name='feature_engineering_pipeline::create_preprocessing_pipeline::output'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 5, 250920), updated=datetime.datetime(2024, 7, 5, 8, 43, 5, 250923), tags=[], latest_version_name='10', latest_version_id=UUID('5e82c1ef-410f-4825-aa95-f2df2d8e4f24')) metadata=None resources=None id=UUID('9f482a3c-5d07-4fa9-967a-6ff454e913bd') permission_denied=False name='train_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 5, 721598), updated=datetime.datetime(2024, 7, 5, 8, 43, 5, 721600), tags=[], latest_version_name='10', latest_version_id=UUID('9945b8aa-e17c-4837-82e0-7b969c3c8155')) metadata=None resources=None id=UUID('52010493-f48b-4629-a1dd-485c540d3df5') permission_denied=False name='test_data'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 6, 448114), updated=datetime.datetime(2024, 7, 5, 8, 43, 6, 448117), tags=[], latest_version_name='10', latest_version_id=UUID('fcda0879-c36c-411c-b920-e8bdea579b5f')) metadata=None resources=None id=UUID('25e4af4f-e376-4fc0-9a1a-4505fd33bc67') permission_denied=False name='train_data_preprocessed'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 6, 989653), updated=datetime.datetime(2024, 7, 5, 8, 43, 6, 989656), tags=[], latest_version_name='10', latest_version_id=UUID('9d28ea71-77f1-4a03-b11a-78406c875fa2')) metadata=None resources=None id=UUID('dbe95cdc-e38c-4edc-98c5-b53b8ec87ba3') permission_denied=False name='test_data_preprocessed'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 7, 487612), updated=datetime.datetime(2024, 7, 5, 8, 43, 7, 487615), tags=[], latest_version_name='10', latest_version_id=UUID('8f4d2a49-54df-43d2-8c66-c11fd0aca09a')) metadata=None resources=None id=UUID('7a45bd8f-706e-4ab1-bcc3-3cd3d1e814dc') permission_denied=False name='pipeline'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 9, 164333), updated=datetime.datetime(2024, 7, 5, 8, 43, 9, 164335), tags=[], latest_version_name='5', latest_version_id=UUID('681688db-3f70-41b8-8073-5ec9593792bf')) metadata=None resources=None id=UUID('17c15bf8-94ea-4260-ba8d-0ec3e7802186') permission_denied=False name='training_pipeline::convert_to_surprise_format::output_0'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 9, 338759), updated=datetime.datetime(2024, 7, 5, 8, 43, 9, 338762), tags=[], latest_version_name='5', latest_version_id=UUID('ce9e53fe-bb94-4327-9bf9-b94249944f94')) metadata=None resources=None id=UUID('ba1ef23b-4cb6-4e64-adc6-4a946eab2a57') permission_denied=False name='training_pipeline::convert_to_surprise_format::output_1'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 9, 506786), updated=datetime.datetime(2024, 7, 5, 8, 43, 9, 506789), tags=[], latest_version_name='5', latest_version_id=UUID('6ff1bf7a-12b4-4d9b-a51f-8efe865dd36b')) metadata=None resources=None id=UUID('36223659-5228-4f9c-99a1-5408919d8b49') permission_denied=False name='training_pipeline::convert_to_surprise_format::output_2'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 11, 51634), updated=datetime.datetime(2024, 7, 5, 8, 43, 11, 51638), tags=[], latest_version_name='3', latest_version_id=UUID('064eb132-2a1e-4b1a-8cba-083bfd346f10')) metadata=None resources=None id=UUID('3d091e33-e156-4a84-88de-e51fe0c046ee') permission_denied=False name='training_pipeline::hp_tuner::output_0'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 11, 205973), updated=datetime.datetime(2024, 7, 5, 8, 43, 11, 205975), tags=[], latest_version_name='3', latest_version_id=UUID('7cfe6cc4-c141-41a3-9424-af4da52f5542')) metadata=None resources=None id=UUID('13ab3fc0-af9a-4002-a4ce-f9cfe54d3929') permission_denied=False name='training_pipeline::hp_tuner::output_1'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 11, 363328), updated=datetime.datetime(2024, 7, 5, 8, 43, 11, 363332), tags=[], latest_version_name='3', latest_version_id=UUID('45ae7e8c-7021-4918-8ddc-1219f935a685')) metadata=None resources=None id=UUID('4062eab2-a012-44de-a4db-2c0752a62ccb') permission_denied=False name='training_pipeline::hp_tuner::output_2'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 11, 517934), updated=datetime.datetime(2024, 7, 5, 8, 43, 11, 517940), tags=[], latest_version_name='3', latest_version_id=UUID('5a62c589-d99d-4213-9d29-3c2f67de24c6')) metadata=None resources=None id=UUID('95fd7784-89ab-403a-ade9-27a4024f8a7d') permission_denied=False name='training_pipeline::hp_tuner::output_3'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 12, 654614), updated=datetime.datetime(2024, 7, 5, 8, 43, 12, 654618), tags=[], latest_version_name='13', latest_version_id=UUID('d670705c-cc5b-45f5-b60c-9963afd2acdb')) metadata=None resources=None id=UUID('2bb05606-6708-423f-a420-367f664244c2') permission_denied=False name='SVD Model'\n","body=ArtifactResponseBody(created=datetime.datetime(2024, 7, 5, 8, 43, 12, 859404), updated=datetime.datetime(2024, 7, 5, 8, 43, 12, 859407), tags=[], latest_version_name='13', latest_version_id=UUID('8124bfe9-0e32-4745-8173-b41c0f694f09')) metadata=None resources=None id=UUID('f4f5a46f-654b-47f4-9769-6144b621dafe') permission_denied=False name='KNN Model'\n"]}],"source":["from zenml.client import Client\n","def print_all_artifact_names():\n","    client = Client()\n","    artifact_names = client.list_artifacts()\n","    print(\"All artifact names:\")\n","    for artifact_name in artifact_names:\n","        print(artifact_name)\n","\n","if __name__ == \"__main__\":\n","    print_all_artifact_names()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["<surprise.prediction_algorithms.random_pred.NormalPredictor at 0x78b8ec7b75b0>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["from zenml.client import Client\n","artifact = Client().get_artifact_version(\"Normal Predictor Model\")\n","artifact.load()"]},{"cell_type":"markdown","metadata":{},"source":["code to print Github folder structure"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Repository Directory Structure:\n","📂 materializers\n","    📄 surprise_materializers.py\n","📂 .zen\n","    📄 config.yaml\n","📄 devcontainer.json\n","📄 launch.json\n","📄 config.yaml\n","📄 main.ipynb\n","📄 .gitignore\n","📄 run.py\n","📂 pipelines\n","    📄 inference_pipeline.py\n","    📂 __pycache__\n","        📄 __init__.cpython-310.pyc\n","        📄 training_pipeline.cpython-310.pyc\n","        📄 feature_engineering_pipeline.cpython-310.pyc\n","    📄 training_pipeline.py\n","    📄 __init__.py\n","    📄 feature_engineering_pipeline.py\n","📂 .git\n","    📄 HEAD\n","    📄 packed-refs\n","    📂 logs\n","        📄 HEAD\n","        📂 refs\n","            📂 heads\n","                📄 Main_after_Feature-Engineering-from-Emma\n","            📂 remotes\n","                📂 origin\n","                    📄 emma\n","                    📄 Hakan\n","                    📄 main\n","                    📄 Silas\n","    📄 FETCH_HEAD\n","    📂 lfs\n","        📂 tmp\n","    📄 description\n","    📂 info\n","        📄 exclude\n","    📄 COMMIT_EDITMSG\n","    📂 hooks\n","        📄 sendemail-validate.sample\n","        📄 commit-msg.sample\n","        📄 applypatch-msg.sample\n","        📄 fsmonitor-watchman.sample\n","        📄 pre-commit.sample\n","        📄 push-to-checkout.sample\n","        📄 pre-rebase.sample\n","        📄 pre-push.sample\n","        📄 prepare-commit-msg.sample\n","        📄 pre-merge-commit.sample\n","        📄 post-update.sample\n","        📄 pre-applypatch.sample\n","        📄 update.sample\n","        📄 pre-receive.sample\n","    📄 config\n","    📂 objects\n","        📂 0c\n","            📄 8eedc24bb4f13a9caf8913868218b66e10e9a7\n","        📂 f3\n","            📄 e7c2b67e19516565e80aa0d90ec51fa20f9c77\n","        📂 9e\n","            📄 72f3d1b4b2de7847392ff51bc1cd01b51d6c34\n","        📂 8e\n","            📄 2df1551b433c998d7f7558463b54624d2faa2a\n","        📂 info\n","        📂 51\n","            📄 361820043aa49272eac80ebaa7bd83d877e948\n","        📂 bf\n","            📄 087ee445c41cbd4f539c1508fa6ef811ed438e\n","        📂 8f\n","            📄 91d40aa4c78c16738ae0c332c21a3f7a9b3c83\n","        📂 e3\n","            📄 e46fc29391ccbdf29ef3be3a5b54a0621e32cc\n","        📂 b2\n","            📄 2122cb7b0d3b02b3610d623571486a882dab72\n","        📂 7a\n","            📄 9147ee2a9014c488733d44b9b2a2c16e674d79\n","        📂 93\n","            📄 de988a676989f89fed4e0849ae8a4dca8e6f3e\n","            📄 ed3675c2d2690a79d7155a07d08952e00f6c4b\n","        📂 ea\n","            📄 d8d030e1924f64c709624cdf51bb604fb7429b\n","        📂 b4\n","            📄 0c8cee27d533e5919b7ffcabbb172874c87c5e\n","        📂 0f\n","            📄 ecfa3303eedf5d41dbbba61885c21fc67d2e50\n","        📂 60\n","            📄 a868877f25c7e2bff5594b606746cbedb46da7\n","        📂 49\n","            📄 3401745197d52675d0f2f9ac91b11132188936\n","        📂 ec\n","            📄 5a0b514b837b4e4d600032a18ae2b17e35bc86\n","        📂 38\n","            📄 adc7e3b4a112385ba089f50a878674bf006171\n","        📂 pack\n","            📄 pack-4f42ab96472c293d8b07e1fc6e10645e61a77b98.idx\n","            📄 pack-a644e7e91fabbaf5a2a33e13bdbdf1c25bbf7e34.pack\n","            📄 pack-a644e7e91fabbaf5a2a33e13bdbdf1c25bbf7e34.rev\n","            📄 pack-4f42ab96472c293d8b07e1fc6e10645e61a77b98.rev\n","            📄 pack-a644e7e91fabbaf5a2a33e13bdbdf1c25bbf7e34.idx\n","            📄 pack-4f42ab96472c293d8b07e1fc6e10645e61a77b98.pack\n","        📂 98\n","            📄 03772b5c6384a35b4fff4f071872e871740b7e\n","    📂 refs\n","        📂 heads\n","            📄 Main_after_Feature-Engineering-from-Emma\n","        📂 tags\n","        📂 remotes\n","            📂 origin\n","                📄 emma\n","                📄 Hakan\n","                📄 main\n","                📄 Silas\n","    📄 index\n","    📂 branches\n","📄 README.md\n","📄 .DS_Store\n","📂 steps\n","    📂 training\n","        📄 model_trainer.py\n","        📄 evaluate_model.py\n","        📂 __pycache__\n","            📄 convert_to_surprise_format.cpython-310.pyc\n","            📄 model_trainer.cpython-310.pyc\n","            📄 hp_tuner.cpython-310.pyc\n","            📄 evaluate_model.cpython-310.pyc\n","        📄 convert_to_surprise_format.py\n","        📄 hp_tuner.py\n","    📂 __pycache__\n","        📄 utils.cpython-310.pyc\n","        📄 __init__.cpython-310.pyc\n","    📄 __init__.py\n","    📂 feature_engineering\n","        📂 __pycache__\n","            📄 create_preprocessing_pipeline.cpython-310.pyc\n","            📄 split_data.cpython-310.pyc\n","            📄 feature_preprocessor.cpython-310.pyc\n","            📄 merged_data.cpython-310.pyc\n","        📂 movie_data\n","            📄 load_movie_data.py\n","            📂 __pycache__\n","                📄 load_movie_data.cpython-310.pyc\n","                📄 clean_movie_data.cpython-310.pyc\n","            📄 clean_movie_data.py\n","        📄 merged_data.py\n","        📄 split_data.py\n","        📄 create_preprocessing_pipeline.py\n","        📂 user_profile\n","            📂 __pycache__\n","                📄 load_rating_data.cpython-310.pyc\n","                📄 preprocess_rating_data.cpython-310.pyc\n","            📄 preprocess_rating_data.py\n","            📄 load_rating_data.py\n","        📄 feature_preprocessor.py\n","    📂 inference\n","        📄 __init__.py\n","        📄 load_inference_rating.py\n","    📄 utils.py\n","📂 data\n","    📄 ratings_small.csv\n","    📄 movies_metadata.csv\n","    📄 inference_ratings.csv\n"]}],"source":["import os\n","\n","def print_directory_structure(start_path='.', indent=''):\n","    for item in os.listdir(start_path):\n","        item_path = os.path.join(start_path, item)\n","        if os.path.isdir(item_path):\n","            print(indent + '📂 ' + item)\n","            print_directory_structure(item_path, indent + '    ')\n","        else:\n","            print(indent + '📄 ' + item)\n","\n","if __name__ == \"__main__\":\n","    print(\"Repository Directory Structure:\")\n","    print_directory_structure()"]},{"cell_type":"markdown","metadata":{},"source":["Librarys for the Dasboard\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","!pip install fastapi uvicorn python-jose[multipart]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install \"zenml[server]==0.60.0\""]},{"cell_type":"markdown","metadata":{},"source":["Open Dashboard:\n","- Username Default\n","- Password: empty"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;35mThe local ZenML server is already configured with the same parameters.\u001b[0m\n","\u001b[1;35mCalling start method...\u001b[0m\n","\u001b[?25l\u001b[32m⠋\u001b[0m Starting service 'LocalZenServer (type: zen_server, flavor: local)'.\n","\n","\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1;35mstart method executed successfully.\u001b[0m\n","\u001b[1;35mConnecting ZenML to the 'local' local ZenML server (http://127.0.0.1:8237).\u001b[0m\n","\u001b[1;35mUpdated the global store configuration.\u001b[0m\n","\u001b[1;35mConnected ZenML to the 'local' local ZenML server (http://127.0.0.1:8237).\u001b[0m\n","\u001b[2;36mThe local ZenML dashboard is available at \u001b[0m\u001b[2;32m'http://127.0.0.1:8237'\u001b[0m\u001b[2;36m. You can \u001b[0m\n","\u001b[2;36mconnect to it using the \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m username and an empty password. \u001b[0m\n","\u001b[1;35mAutomatically opening the dashboard in your browser. To disable this, set the env variable AUTO_OPEN_DASHBOARD=false.\u001b[0m\n"]}],"source":["!zenml up"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
